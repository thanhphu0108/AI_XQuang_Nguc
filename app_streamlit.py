import streamlit as st
import cv2
import numpy as np
from ultralytics import YOLO
import os
import torch
import time
from datetime import datetime
from PIL import Image
import pandas as pd
import pydicom
import shutil
import hashlib
import base64
import json
from openai import OpenAI

# ================= 1. C·∫§U H√åNH TRANG WEB =================
st.set_page_config(
    page_title="AI Hospital (AI Teacher Mode)",
    page_icon="üè•",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS GIAO DI·ªÜN
st.markdown("""
<style>
    .main { background-color: #f4f6f9; }
    .report-container { background-color: white; padding: 40px; border-radius: 5px; box-shadow: 0 4px 10px rgba(0,0,0,0.1); }
    .stButton>button { width: 100%; border-radius: 8px; font-weight: bold; height: 45px; }
    .gpt-suggestion { background-color: #e8f5e9; padding: 10px; border-radius: 5px; border-left: 5px solid #4caf50; margin-bottom: 10px; }
</style>
""", unsafe_allow_html=True)

# ================= 2. C·∫§U H√åNH H·ªÜ TH·ªêNG =================
BASE_PATH = os.path.dirname(os.path.abspath(__file__))
MODELS_DIR = os.path.join(BASE_PATH, "models")
HISTORY_DIR = os.path.join(BASE_PATH, "history")
IMAGES_DIR = os.path.join(HISTORY_DIR, "images")
LOG_FILE = os.path.join(HISTORY_DIR, "log_book.csv")
TRAIN_DATA_DIR = os.path.join(BASE_PATH, "dataset_yolo_ready")

os.makedirs(IMAGES_DIR, exist_ok=True)

# DANH S√ÅCH B·ªÜNH CHU·∫®N (ƒê·ªÉ √©p ChatGPT tr·∫£ l·ªùi ƒë√∫ng form n√†y)
LABEL_MAP = {
    "B√¨nh th∆∞·ªùng (Normal)": "Normal",
    "B√≥ng tim to (Cardiomegaly)": "Cardiomegaly",
    "Vi√™m ph·ªïi (Pneumonia)": "Pneumonia",
    "Tr√†n d·ªãch m√†ng ph·ªïi (Effusion)": "Effusion",
    "Tr√†n kh√≠ m√†ng ph·ªïi (Pneumothorax)": "Pneumothorax",
    "U ph·ªïi / N·ªët m·ªù (Nodule/Mass)": "Nodule_Mass",
    "X∆° h√≥a / Lao ph·ªïi (Fibrosis/TB)": "Fibrosis_TB",
    "G√£y x∆∞∆°ng (Fracture)": "Fracture",
    "D√†y d√≠nh m√†ng ph·ªïi (Pleural Thickening)": "Pleural_Thickening",
    "Kh√°c / T·∫°p √¢m (Other)": "Other"
}
# T·∫°o list t√™n b·ªánh ƒë·ªÉ ƒë∆∞a v√†o Prompt
ALLOWED_LABELS = list(LABEL_MAP.keys())

if not os.path.exists(LOG_FILE):
    pd.DataFrame(columns=["ID", "Time", "Result", "Image_Path", "Patient_Info", 
                          "Feedback_1", "Label_1", "Feedback_2", "Label_2", "GPT_Reasoning"]).to_csv(LOG_FILE, index=False)

DOCTOR_ROSTER = {
    "ANATOMY": "Dr_Anatomy.pt",      
    "PNEUMOTHORAX": "Dr_Pneumothorax.pt", "PNEUMONIA": "Dr_Pneumonia.pt",    
    "TUMOR": "Dr_Tumor.pt", "EFFUSION": "Dr_Effusion.pt",     
    "OPACITY": "Dr_Opacity.pt", "HEART": "Dr_Heart.pt"         
}

# ================= 3. CORE FUNCTIONS =================
@st.cache_resource
def load_models():
    loaded_models = {}
    for role, filename in DOCTOR_ROSTER.items():
        path = os.path.join(MODELS_DIR, filename)
        if os.path.exists(path):
            try: loaded_models[role] = YOLO(path)
            except: pass
    return loaded_models

MODELS = load_models()

def encode_image_to_base64(image_path):
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode('utf-8')

# --- H√ÄM H·ªéI CHATGPT ƒê·ªÇ L·∫§Y NH√ÉN ---
def ask_gpt_for_label(api_key, image_path):
    try:
        client = OpenAI(api_key=api_key)
        base64_image = encode_image_to_base64(image_path)
        
        # Prompt √©p ki·ªÉu tr·∫£ v·ªÅ JSON
        labels_str = ", ".join([f"'{l}'" for l in ALLOWED_LABELS])
        prompt = f"""
        B·∫°n l√† b√°c sƒ© ch·∫©n ƒëo√°n h√¨nh ·∫£nh chuy√™n gia. H√£y xem phim X-quang n√†y.
        Nhi·ªám v·ª•:
        1. X√°c ƒë·ªãnh c√°c b·ªánh l√Ω c√≥ trong ·∫£nh.
        2. CH·ªà ƒê∆Ø·ª¢C CH·ªåN nh√£n t·ª´ danh s√°ch sau: [{labels_str}].
        3. N·∫øu b√¨nh th∆∞·ªùng, ch·ªçn 'B√¨nh th∆∞·ªùng (Normal)'.
        
        Tr·∫£ v·ªÅ k·∫øt qu·∫£ ƒë·ªãnh d·∫°ng JSON thu·∫ßn t√∫y (kh√¥ng markdown) nh∆∞ sau:
        {{
            "labels": ["T√™n b·ªánh 1", "T√™n b·ªánh 2"],
            "reasoning": "Gi·∫£i th√≠ch ng·∫Øn g·ªçn t·∫°i sao ch·ªçn (ti·∫øng Vi·ªát)..."
        }}
        """
        
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "You are a helpful medical AI assistant. Output JSON only."},
                {"role": "user", "content": [
                    {"type": "text", "text": prompt},
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}}
                ]}
            ],
            max_tokens=300,
            response_format={"type": "json_object"}
        )
        content = response.choices[0].message.content
        return json.loads(content)
    except Exception as e:
        return {"labels": [], "reasoning": f"L·ªói: {str(e)}"}

def read_dicom_image(file_buffer):
    try:
        ds = pydicom.dcmread(file_buffer)
        p_name = str(ds.get("PatientName", "Anonymous")).replace('^', ' ').strip()
        p_id = str(ds.get("PatientID", "Unknown"))
        img = ds.pixel_array.astype(float)
        img = (np.maximum(img, 0) / img.max()) * 255.0
        img = np.uint8(img)
        if ds.get("PhotometricInterpretation") == "MONOCHROME1": img = 255 - img
        if len(img.shape) == 2: img_rgb = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)
        else: img_rgb = img
        return img_rgb, f"{p_name} ({p_id})"
    except: return None, "L·ªói DICOM"

def save_case(img_cv, patient_info="N/A"):
    img_id = datetime.now().strftime("%d%m%Y%H%M%S") 
    file_name = f"XRAY_{img_id}.jpg"
    save_path = os.path.join(IMAGES_DIR, file_name)
    try: cv2.imwrite(save_path, cv2.cvtColor(img_cv, cv2.COLOR_RGB2BGR))
    except: pass
    new_record = {
        "ID": img_id, "Time": datetime.now().strftime("%d/%m/%Y %H:%M"), 
        "Result": "ƒêang ch·ªù", "Image_Path": file_name, "Patient_Info": patient_info, 
        "Feedback_1": "Ch∆∞a ƒë√°nh gi√°", "Label_1": "", "Feedback_2": "Ch∆∞a ƒë√°nh gi√°", "Label_2": "", "GPT_Reasoning": ""
    }
    try:
        df = pd.read_csv(LOG_FILE)
        df = pd.concat([pd.DataFrame([new_record]), df], ignore_index=True)
        df.to_csv(LOG_FILE, index=False)
    except: pass
    return img_id

def update_feedback_slot(selected_id, feedback_value, label_value, slot, gpt_reason=""):
    try:
        df = pd.read_csv(LOG_FILE)
        df['ID'] = df['ID'].astype(str)
        selected_id = str(selected_id)
        if slot == 1:
            df.loc[df["ID"] == selected_id, "Feedback_1"] = feedback_value
            df.loc[df["ID"] == selected_id, "Label_1"] = label_value
        elif slot == 2:
            df.loc[df["ID"] == selected_id, "Feedback_2"] = feedback_value
            df.loc[df["ID"] == selected_id, "Label_2"] = label_value
        
        if gpt_reason:
             df.loc[df["ID"] == selected_id, "GPT_Reasoning"] = gpt_reason
             
        df.to_csv(LOG_FILE, index=False)
        return True
    except: return False

def get_final_label(row):
    if pd.notna(row["Label_2"]) and row["Label_2"] != "" and row["Feedback_2"] != "Ch∆∞a ƒë√°nh gi√°": return row["Label_2"]
    elif pd.notna(row["Label_1"]) and row["Label_1"] != "" and row["Feedback_1"] != "Ch∆∞a ƒë√°nh gi√°": return row["Label_1"]
    return ""

def export_dataset():
    if not os.path.exists(LOG_FILE): return "No data", None
    if os.path.exists(TRAIN_DATA_DIR): shutil.rmtree(TRAIN_DATA_DIR)
    os.makedirs(os.path.join(TRAIN_DATA_DIR, "images"), exist_ok=True)
    os.makedirs(os.path.join(TRAIN_DATA_DIR, "labels"), exist_ok=True)
    for en in LABEL_MAP.values(): os.makedirs(os.path.join(TRAIN_DATA_DIR, "classified", en), exist_ok=True)
    
    df = pd.read_csv(LOG_FILE)
    count = 0
    anatomy_model = MODELS.get("ANATOMY")
    
    for idx, row in df.iterrows():
        labels = get_final_label(row)
        img_src = os.path.join(IMAGES_DIR, str(row["Image_Path"]))
        if labels and os.path.exists(img_src):
            # Classify Folder
            for lbl in labels.split(";"):
                en_name = LABEL_MAP.get(lbl.strip())
                if en_name: shutil.copy(img_src, os.path.join(TRAIN_DATA_DIR, "classified", en_name, row["Image_Path"]))
            
            # YOLO Detection
            pri_lbl = labels.split(";")[0].strip()
            en_pre = LABEL_MAP.get(pri_lbl, "Unk")
            dst_img = os.path.join(TRAIN_DATA_DIR, "images", f"{en_pre}_{row['Image_Path']}")
            shutil.copy(img_src, dst_img)
            
            # Auto Label
            if anatomy_model:
                try:
                    res = anatomy_model(img_src, verbose=False)[0]
                    txt = ""
                    for box in res.boxes:
                        c, x, y, w, h = int(box.cls[0]), *box.xywhn[0].tolist()
                        txt += f"{c} {x:.6f} {y:.6f} {w:.6f} {h:.6f}\n"
                    with open(dst_img.replace("images", "labels").replace(".jpg", ".txt"), "w") as f: f.write(txt)
                except: pass
            count += 1
            
    shutil.make_archive(TRAIN_DATA_DIR, 'zip', TRAIN_DATA_DIR)
    return f"Exported {count} files", f"{TRAIN_DATA_DIR}.zip"

# ================= 7. GIAO DI·ªÜN CH√çNH =================
with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/3063/3063176.png", width=60)
    st.title("ƒêI·ªÄU KHI·ªÇN")
    
    # -----------------------------------------------------------
    # B·∫ÆT BU·ªòC NH·∫¨P KEY TH·ª¶ C√îNG (Kh√¥ng d√πng secrets)
    # -----------------------------------------------------------
    api_key = st.text_input("üîë OpenAI API Key:", type="password", help="Nh·∫≠p Key ƒë·ªÉ d√πng t√≠nh nƒÉng AI Teacher")
    
    mode = st.radio("Ch·ª©c nƒÉng:", ["üîç Ph√¢n T√≠ch & Upload", "üìÇ H·ªôi Ch·∫©n (AI Teacher)", "üõ†Ô∏è Xu·∫•t Dataset"])

if mode == "üîç Ph√¢n T√≠ch & Upload":
    st.title("üè• T·∫¢I ·∫¢NH L√äN H·ªÜ TH·ªêNG")
    uploaded_file = st.file_uploader("T·∫£i ·∫£nh X-quang:", type=["jpg", "png", "dcm"])
    
    def process_image(f):
        fname = f.name.lower()
        img_rgb, p_info = None, "·∫®n danh"
        if fname.endswith('dcm'): img_rgb, p_info = read_dicom_image(f)
        else: 
            file_bytes = np.asarray(bytearray(f.read()), dtype=np.uint8)
            img_rgb = cv2.cvtColor(cv2.imdecode(file_bytes, 1), cv2.COLOR_BGR2RGB)
        
        if img_rgb is not None:
            save_case(img_rgb, p_info)
            return True, p_info
        return False, ""

    if uploaded_file and st.button("üöÄ X·ª≠ l√Ω & L∆∞u"):
        img_out, p_info = process_image(uploaded_file)
        if img_out: st.success("ƒê√£ l∆∞u v√†o kho d·ªØ li·ªáu! Chuy·ªÉn sang tab H·ªôi Ch·∫©n ƒë·ªÉ g√°n nh√£n.")

elif mode == "üìÇ H·ªôi Ch·∫©n (AI Teacher)":
    st.title("üìÇ H·ªòI CH·∫®N & AI G√ÅN NH√ÉN")
    
    if os.path.exists(LOG_FILE):
        df = pd.read_csv(LOG_FILE)
        df['ID'] = df['ID'].astype(str)
        df = df.iloc[::-1] # M·ªõi nh·∫•t l√™n ƒë·∫ßu
        
        # Ch·ªçn ca
        id_list = df["ID"].unique()
        selected_id = st.selectbox("üëâ Ch·ªçn M√£ h·ªì s∆°:", id_list)
        
        if selected_id:
            record = df[df["ID"] == selected_id].iloc[0]
            col_img, col_tool = st.columns([1, 1])
            
            img_path = os.path.join(IMAGES_DIR, record["Image_Path"])
            
            with col_img:
                if os.path.exists(img_path): st.image(img_path, use_container_width=True)
            
            with col_tool:
                st.info(f"B·ªánh nh√¢n: {record['Patient_Info']}")
                
                # --- AI TEACHER BUTTON ---
                gpt_labels = []
                gpt_reason = ""
                
                # N√∫t b·∫•m ch·ªâ ho·∫°t ƒë·ªông khi c√≥ API Key
                if api_key:
                    if st.button("üß† Xin √Ω ki·∫øn ChatGPT (Auto-Label)"):
                        with st.spinner("ChatGPT ƒëang ph√¢n t√≠ch v√† ch·ªçn nh√£n..."):
                            gpt_res = ask_gpt_for_label(api_key, img_path)
                            gpt_labels = gpt_res.get("labels", [])
                            gpt_reason = gpt_res.get("reasoning", "")
                            
                            if gpt_labels:
                                st.markdown(f"""
                                <div class="gpt-suggestion">
                                    <b>ü§ñ ChatGPT G·ª£i √Ω:</b> {', '.join(gpt_labels)}<br>
                                    <i>"{gpt_reason}"</i>
                                </div>
                                """, unsafe_allow_html=True)
                            else: st.error("ChatGPT kh√¥ng tr·∫£ v·ªÅ nh√£n n√†o ho·∫∑c l·ªói (Ki·ªÉm tra l·∫°i Key).")
                else:
                    st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p OpenAI API Key ·ªü c·ªôt b√™n tr√°i ƒë·ªÉ d√πng t√≠nh nƒÉng n√†y!")

                st.markdown("---")
                # --- FORM ƒê√ÅNH GI√Å ---
                fb1 = record.get("Feedback_1", "Ch∆∞a ƒë√°nh gi√°")
                lb1 = record.get("Label_1", "")
                
                # T·ª± ƒë·ªông ƒëi·ªÅn n·∫øu c√≥ GPT
                default_labels = gpt_labels if gpt_labels else (lb1.split("; ") if lb1 else [])
                # L·ªçc l·∫°i ƒë·ªÉ ch·∫Øc ch·∫Øn label n·∫±m trong list cho ph√©p
                valid_defaults = [l for l in default_labels if l in ALLOWED_LABELS]
                
                st.write("### üìù K·∫øt lu·∫≠n chuy√™n m√¥n:")
                new_fb = st.radio("ƒê√°nh gi√°:", ["Ch∆∞a ƒë√°nh gi√°", "‚úÖ ƒê·ªìng thu·∫≠n", "‚ùå Sai (S·ª≠a l·∫°i)"], 
                                  index=0 if fb1 == "Ch∆∞a ƒë√°nh gi√°" else (1 if "ƒê·ªìng thu·∫≠n" in fb1 else 2))
                
                final_labels = st.multiselect("B·ªánh l√Ω x√°c ƒë·ªãnh:", ALLOWED_LABELS, default=valid_defaults)
                
                if st.button("üíæ L∆ØU K·∫æT QU·∫¢ (TRAINING DATA)"):
                    lbl_str = "; ".join(final_labels)
                    # L∆∞u v√†o Slot 1 (ho·∫∑c logic 2 slot t√πy b·∫°n, ·ªü ƒë√¢y l√†m ƒë∆°n gi·∫£n 1 slot chu·∫©n)
                    update_feedback_slot(selected_id, new_fb, lbl_str, 1, gpt_reason)
                    st.success("ƒê√£ l∆∞u! D·ªØ li·ªáu n√†y s·∫Ω ƒë∆∞·ª£c d√πng ƒë·ªÉ train.")
                    time.sleep(0.5)
                    st.rerun()

elif mode == "üõ†Ô∏è Xu·∫•t Dataset":
    st.title("üõ†Ô∏è XU·∫§T DATASET")
    if st.button("üöÄ T·∫†O DATASET T·ª™ D·ªÆ LI·ªÜU ƒê√É G√ÅN NH√ÉN"):
        msg, zip_f = export_dataset()
        if zip_f:
            st.success(msg)
            with open(zip_f, "rb") as f: st.download_button("üì• T·∫£i v·ªÅ", f, "dataset.zip")